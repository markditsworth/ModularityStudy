{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed and Quality of Katz-Eigen Community Detection vs Louvain\n",
    "\n",
    "### Main Take-aways\n",
    " Network (nodes, edges)  | Louvain Speed | KE Speed | Louvain Q/Qmax | KE Q/Qmax |\n",
    "-----------------------  |:-------------:|:--------:|:--------------:|:---------:|\n",
    "Amazon Product (328,679) | 0.472 s       | 0.089 s  | 0.882          | 0.968     |\n",
    "AdHoc BA (1000,16975)    | 10.1 s        | 0.570 s  | 0.988          | 0.992     |\n",
    "AdHoc BA (1000,5032)     | 13.7 s        | 0.276 s  | 0.308          | 0.956     |\n",
    "\n",
    "** In this example, agglomerative clustering results in sub-par seperation of clusters in the Katz-eigen plot. It is shown that the louvain communities are actually representative of the distinct clusters in the katz-eigen plot. And by joining louvain communites together based on their placement in the katz-eigen plot, a much higher modularity (0.98) is achieved.\n",
    "\n",
    "*** In this example, agglomerative clustering peforms very poorly, and as a result, results in poor communities. Again, by joining louvain communites together based on their placement in the katz-eigen plot, a much higher modularity (0.94) is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from clusteringAlgo import lineClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the speed of the Katz-eigen plot method of community detection with that of Louvain community detection, using the 328-node Amazon product network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz(G,tol=0.01,max_iter=1000,alpha=0.001,beta=1):\n",
    "    iteration = 0\n",
    "    centrality = np.zeros(G.num_nodes)\n",
    "    while iteration < max_iter:\n",
    "        iteration += 1          # increment iteration count\n",
    "        centrality_old = centrality.copy()\n",
    "\n",
    "        for node in G.nodes_():\n",
    "            Ax = 0\n",
    "            for neighbor in G.neighbors_(node):\n",
    "                weight = G.weight_(G.edge_idx_(neighbor,node))\n",
    "                Ax += np.multiply(centrality[neighbor],weight)\n",
    "\n",
    "                #Ax += centrality[neighbor]      #exclude weight due to overflow in multiplication\n",
    "\n",
    "            centrality[node] = np.multiply(alpha,Ax)+beta\n",
    "\n",
    "        if np.sum(np.abs(np.subtract(centrality,centrality_old))) < tol:\n",
    "            return centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modular_graph(Size1, Size2, edges1, edges2, common, katz_alpha=0.001):\n",
    "    g1 = zen.generating.barabasi_albert(Size1,edges1)\n",
    "    avgDeg1 = (2.0 * g1.num_edges)/g1.num_nodes\n",
    "    lcc1 = np.mean(zen.algorithms.clustering.lcc_(g1))\n",
    "    \n",
    "    g2 = zen.generating.barabasi_albert(Size2,edges2)\n",
    "    avgDeg2 = (2.0 * g2.num_edges)/g2.num_nodes\n",
    "    lcc2 = np.mean(zen.algorithms.clustering.lcc_(g2))\n",
    "    \n",
    "    Size = Size1 + Size2\n",
    "    G = zen.Graph()\n",
    "    for i in range(Size):\n",
    "        G.add_node(i)\n",
    "\n",
    "    for edge in g1.edges_iter():\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "        G.add_edge(u,v)\n",
    "\n",
    "    for edge in g2.edges_iter():\n",
    "        u = edge[0]+Size1\n",
    "        v = edge[1]+Size1\n",
    "        G.add_edge(u,v)\n",
    "\n",
    "    # Select random pairs of nodes to connect the subgraphs\n",
    "    join_nodes = np.empty((common,2),dtype=np.int64)\n",
    "    nodes1 = np.random.randint(0,Size1,size=common)\n",
    "    nodes2 = np.random.randint(Size1,Size,size=common)\n",
    "    join_nodes[:,0] = nodes1\n",
    "    join_nodes[:,1] = nodes2\n",
    "\n",
    "    for edge in join_nodes:\n",
    "        if not G.has_edge(edge[0],edge[1]):\n",
    "            G.add_edge(edge[0],edge[1])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modularity(G,classDict,classList):\n",
    "    Q = zen.algorithms.modularity(G,classDict)\n",
    "    # Maximum Modularity\n",
    "    count=0.0\n",
    "    for e in G.edges():\n",
    "        n1 = G.node_idx(e[0])\n",
    "        n2 = G.node_idx(e[1])\n",
    "        if classList[n1] == classList[n2]:\n",
    "            count += 1\n",
    "    same = count / G.num_edges\n",
    "    rand = same - Q\n",
    "    qmax = 1 - rand\n",
    "    return Q, qmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x,y,m):\n",
    "    '''\n",
    "    Not mean-squared-error, just too lazy to chance the function name.\n",
    "    Measures the orthogonal distance points are from the line through origin with slope m\n",
    "    '''\n",
    "    x_ = (m*y+x)/(m**2 + 1)\n",
    "    y_ = (y*(m**2) + m*x)/(m**2 + 1)\n",
    "    return np.sum(np.power(x-x_,2) + np.power(y-y_,2))\n",
    "    \n",
    "\n",
    "def slope(angle):\n",
    "    '''\n",
    "    Calculates linear slope of line with angle from x-axis (radians)\n",
    "    '''\n",
    "    return np.tan(angle)\n",
    "    \n",
    "def bound(x, y, slope, lineU, lineL):\n",
    "    '''\n",
    "    returns subset of x,y that are between the lines lineU and lineL\n",
    "    '''\n",
    "    upper = lineU(x,slope)\n",
    "    lower = lineL(x,slope)\n",
    "    return np.logical_and(y>=lower, y<=upper)\n",
    "\n",
    "def get_offsets(m,d):\n",
    "    '''\n",
    "    calculates the shift of a line that has an orthogonal distance d\n",
    "    from a line through the origin with slope m\n",
    "    '''\n",
    "    A = 1./(m**2) + 1\n",
    "    B = -2*A\n",
    "    C = (1./(m**2))+1 - d**2\n",
    "    \n",
    "    x1 = (-B + np.sqrt(B**2 - 4*A*C))/(2*A)\n",
    "    \n",
    "    y1 = m + (1./m) - (x1/m)\n",
    "    \n",
    "    b1 = y1 - m*x1\n",
    "    return b1\n",
    "\n",
    "def lineFinder(x, y, dtheta=0.01, dx=0.05):\n",
    "    theta=0\n",
    "    \n",
    "    line = lambda x,m: m*x\n",
    "    b_up = lambda x,m: m*(x)-get_offsets(m,dx)\n",
    "    b_low= lambda x,m: m*(x)+get_offsets(m,dx)\n",
    "    \n",
    "    thetas = np.arange(1e-4,np.pi/2,dtheta)\n",
    "    error = np.empty(len(thetas))\n",
    "    \n",
    "    for i,theta in enumerate(thetas):\n",
    "        m = slope(theta)\n",
    "        X = x[bound(x,y,m,b_up,b_low)]\n",
    "        Y = y[bound(x,y,m,b_up,b_low)]\n",
    "        error[i] = MSE(X,Y,m)*(len(X)/float(len(x)))\n",
    "    \n",
    "    return thetas, error\n",
    "\n",
    "def optimizeAngles(angle,error,N,plot=False):\n",
    "    N=10\n",
    "    x = pd.Series(error).rolling(window=N).mean().iloc[N-1:].values\n",
    "    x_ = np.diff(x)\n",
    "    t = angle[N:]\n",
    "    ang = []\n",
    "    for i in range(len(x_)):\n",
    "        if i != 0 and i != len(x_)-1:\n",
    "            if x_[i-1] < 0 and x_[i] >= 0:\n",
    "                ang.append(t[i])\n",
    "    if plot:\n",
    "        for a in ang:\n",
    "            plt.vlines(ymin=np.min(x),ymax=np.max(x),x=a*180/np.pi,linestyle='--',color='grey')\n",
    "        plt.plot(angle[N-1:]*180/np.pi,x)\n",
    "        plt.xlabel('Angle (deg.)')\n",
    "        plt.ylabel('Sum of Squared Orth. Error')\n",
    "        plt.title('Identification of Local Minima')\n",
    "        plt.show()\n",
    "\n",
    "    return ang\n",
    "\n",
    "def getGroups(x,y,angles):\n",
    "    if len(angles) == 1:\n",
    "        m = slope(angles[0])\n",
    "        y_ = x*m\n",
    "        g1 = np.where(y<=y_)[0]\n",
    "        g2 = np.where(y>y_)[0]\n",
    "        return [g1,g2]\n",
    "    elif len(angles) == 2:\n",
    "        m1 = slope(angles[0])\n",
    "        m2 = slope(angles[1])\n",
    "        y1_ = x*m1\n",
    "        y2_ = x*m2\n",
    "        g1 = np.where(y<=y1_)[0]\n",
    "        g2 = np.where(np.logical_and(y>y1_,y<=y2_))[0]\n",
    "        g3 = np.where(y>y2_)[0]\n",
    "        return [g1,g2,g3]\n",
    "    \n",
    "def lineClustering(x,y, dtheta=0.01, dx=0.05, window=10, plot=False):\n",
    "    angles, errors = lineFinder(x,y,dtheta=dtheta,dx=dx)\n",
    "    best_angles = optimizeAngles(angles,errors,window,plot=plot)\n",
    "    clusters = getGroups(x,y,best_angles)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ke_community_detection(G,dtheta=0.01,dx=0.5,window=10):\n",
    "    evc = zen.algorithms.eigenvector_centrality_(G)\n",
    "    kc = katz(G,alpha=1e-4)\n",
    "    \n",
    "    #scale\n",
    "    evc = evc - np.min(evc)\n",
    "    evc = evc / np.max(evc)\n",
    "    kc  = kc - np.min(kc)\n",
    "    kc = kc / np.max(kc)\n",
    "    \n",
    "    clusters = lineClustering(evc,kc,dtheta=dtheta,dx=dx,window=window)\n",
    "    \n",
    "    ClassDict = {}\n",
    "    ClassList = np.zeros(G.num_nodes)\n",
    "    for i,c in enumerate(clusters):\n",
    "        ClassDict[i] = [G.node_object(x) for x in c]\n",
    "        ClassList[c]=i\n",
    "\n",
    "    q,qmax = modularity(G,ClassDict,ClassList)\n",
    "    print '%d communities found.'%(i+1)\n",
    "    print 'Q:            %.3f'%q\n",
    "    print 'Normalized Q: %.3f'%(q/qmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zen.algorithms.community import louvain\n",
    "def louvain_community_detection(G):\n",
    "    cset = louvain(G)\n",
    "\n",
    "    comm_dict = {}\n",
    "    comm_list = np.zeros(G.num_nodes)\n",
    "    for i,community in enumerate(cset.communities()):\n",
    "        comm_dict[i] = community.nodes()\n",
    "        comm_list[community.nodes_()] = i\n",
    "\n",
    "    q,qmax = modularity(G,comm_dict,comm_list)\n",
    "    print '%d communities found.'%(i+1)\n",
    "    print 'Q:            %.3f'%q\n",
    "    print 'Normalized Q: %.3f'%(q/qmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Amazon Product Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = zen.io.gml.read('amazon_product.gml',weight_fxn=lambda x: x['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 communities found.\n",
      "Q:            0.359\n",
      "Normalized Q: 0.769\n",
      "CPU times: user 33.4 ms, sys: 1.63 ms, total: 35 ms\n",
      "Wall time: 31.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ke_community_detection(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 communities found.\n",
      "Q:            0.801\n",
      "Normalized Q: 0.882\n",
      "CPU times: user 370 ms, sys: 795 µs, total: 371 ms\n",
      "Wall time: 371 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "louvain_community_detection(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on synthetic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 1000\n",
      "Edges: 16975\n"
     ]
    }
   ],
   "source": [
    "G_synth = modular_graph(500,500,15,20,100,katz_alpha=1e-4)\n",
    "print \"Nodes: %d\"%G_synth.num_nodes\n",
    "print \"Edges: %d\"%G_synth.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 communities found.\n",
      "Q:            0.480\n",
      "Normalized Q: 0.964\n",
      "CPU times: user 329 ms, sys: 31.2 ms, total: 360 ms\n",
      "Wall time: 329 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ke_community_detection(G_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 communities found.\n",
      "Q:            0.485\n",
      "Normalized Q: 0.988\n",
      "CPU times: user 11.8 s, sys: 0 ns, total: 11.8 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "louvain_community_detection(G_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 1000\n",
      "Edges: 5032\n"
     ]
    }
   ],
   "source": [
    "G_synth = modular_graph(500,500,2,8,100,katz_alpha=1e-4)\n",
    "print \"Nodes: %d\"%G_synth.num_nodes\n",
    "print \"Edges: %d\"%G_synth.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 communities found.\n",
      "Q:            0.099\n",
      "Normalized Q: 0.190\n",
      "CPU times: user 122 ms, sys: 5.3 ms, total: 127 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ke_community_detection(G_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 communities found.\n",
      "Q:            0.273\n",
      "Normalized Q: 0.304\n",
      "CPU times: user 21.2 s, sys: 0 ns, total: 21.2 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "louvain_community_detection(G_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 2000\n",
      "Edges: 11035\n"
     ]
    }
   ],
   "source": [
    "G_synth = modular_graph(1000,1000,4,7,100,katz_alpha=1e-4)\n",
    "print \"Nodes: %d\"%G_synth.num_nodes\n",
    "print \"Edges: %d\"%G_synth.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 communities found.\n",
      "Q:            0.228\n",
      "Normalized Q: 0.484\n",
      "CPU times: user 228 ms, sys: 14.8 ms, total: 243 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ke_community_detection(G_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 communities found.\n",
      "Q:            0.291\n",
      "Normalized Q: 0.313\n",
      "CPU times: user 2min 2s, sys: 1.14 ms, total: 2min 2s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "louvain_community_detection(G_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
